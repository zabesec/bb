import json
import os
import random
import re
import subprocess
import sys
import time

import requests

COOKIES = []
cookie_index = 0
PROGRESS_FILE = "/app/output/progress.json"
SCANNED_FILE = "/app/output/scanned.txt"


def fetch_from_url(url):
    cmd = ["curl", "-s", url]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)

        if result.returncode != 0:
            return []

        items = []
        for line in result.stdout.split("\n"):
            line = line.strip()
            if line and not line.startswith("#"):
                items.append(line)

        return items

    except Exception as e:
        return []


def load_cookies(cookie_url):
    global COOKIES

    cookies = fetch_from_url(cookie_url)
    if cookies:
        COOKIES.extend(cookies)
        print(f"[+] Loaded {len(cookies)} cookies")
        return True

    return False


def extract_root_domain(domain):
    domain = domain.lower().strip()

    domain = re.sub(r"^https?://", "", domain)
    domain = re.sub(r"/.*$", "", domain)
    domain = domain.split(":")[0]

    parts = domain.split(".")

    if len(parts) >= 2:
        return ".".join(parts[-2:])

    return domain


def load_progress():
    if os.path.exists(PROGRESS_FILE):
        try:
            with open(PROGRESS_FILE, "r") as f:
                return json.load(f)
        except:
            return {"last_index": 0, "total_found": 0}
    return {"last_index": 0, "total_found": 0}


def save_progress(index, total_found):
    os.makedirs(os.path.dirname(PROGRESS_FILE), exist_ok=True)
    with open(PROGRESS_FILE, "w") as f:
        json.dump({"last_index": index, "total_found": total_found}, f)


def mark_scanned(domain):
    os.makedirs(os.path.dirname(SCANNED_FILE), exist_ok=True)
    with open(SCANNED_FILE, "a") as f:
        f.write(f"{domain}\n")


def load_domains(targets_url):
    all_lines = fetch_from_url(targets_url)

    if not all_lines:
        return []

    root_domains = set()
    for domain in all_lines:
        root = extract_root_domain(domain)
        if root:
            root_domains.add(root)

    unique_domains = sorted(list(root_domains))

    print(f"[+] Total lines: {len(all_lines)}")
    print(f"[+] Unique root domains: {len(unique_domains)}")

    return unique_domains


def get_next_cookie():
    global cookie_index
    if not COOKIES:
        return None
    cookie = COOKIES[cookie_index]
    cookie_index = (cookie_index + 1) % len(COOKIES)
    return cookie


def scrape_shodan(query, domain):
    cookie = get_next_cookie()
    if not cookie:
        return [], None

    search_query = f"http.favicon.hash:{query} Ssl:{domain}"
    url = f"https://www.shodan.io/search?query={search_query.replace(':', '%3A').replace(' ', '+')}"

    print(f"[+] Searching: {domain}")

    cmd = [
        "curl",
        "-s",
        "-H",
        f"Cookie: {cookie}",
        "-H",
        "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        url,
    ]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        html = result.stdout

        if not html:
            return [], None

        targets = []
        result_blocks = html.split('<div class="result">')

        for block in result_blocks[1:]:
            ip = None
            port = 443

            ip_match = re.search(r'href="/host/([\d\.]+)"', block)
            if ip_match:
                ip = ip_match.group(1)

            url_match = re.search(r'href="https?://([\d\.]+):(\d+)"', block)
            if url_match:
                ip = url_match.group(1)
                port = int(url_match.group(2))

            if ip:
                targets.append(f"{ip}:{port}")

        unique_targets = list(set(targets))

        return unique_targets, url

    except:
        return [], None


def send_discord_webhook(webhook_url, domain, targets, search_url):
    embed = {
        "title": "ðŸŽ¯ Targets Found",
        "description": f"**Domain:** `{domain}`\n**Results:** {len(targets)} targets",
        "color": 3066993,
        "fields": [
            {
                "name": "Search URL",
                "value": f"[View on Shodan]({search_url})",
                "inline": False,
            },
            {
                "name": "Targets",
                "value": "```\n"
                + "\n".join(targets[:20])
                + ("\n..." if len(targets) > 20 else "")
                + "\n```",
                "inline": False,
            },
        ],
    }

    payload = {"embeds": [embed]}

    try:
        response = requests.post(webhook_url, json=payload, timeout=10)
        if response.status_code == 204:
            print(f"[+] Sent to Discord: {domain} ({len(targets)} targets)")
            return True
        else:
            print(f"[-] Discord webhook failed: {response.status_code}")
            return False
    except Exception as e:
        print(f"[-] Discord error: {e}")
        return False


def main():
    print("=" * 60)
    print("CVE-2023-36845 Scanner")
    print("=" * 60)

    cookie_url = os.getenv("COOKIE_URL")
    targets_url = os.getenv("TARGETS_URL")
    webhook_url = os.getenv("DISCORD_WEBHOOK_URL")

    if not cookie_url or not targets_url or not webhook_url:
        print("[-] Missing environment variables:")
        print("    COOKIE_URL, TARGETS_URL, DISCORD_WEBHOOK_URL")
        sys.exit(1)

    if not load_cookies(cookie_url):
        print("[-] Failed to load cookies")
        sys.exit(1)

    domains = load_domains(targets_url)

    if not domains:
        print("[-] No domains loaded")
        sys.exit(1)

    progress = load_progress()
    start_index = progress["last_index"]
    total_targets = progress["total_found"]

    if start_index > 0:
        print(f"[+] Resuming from index {start_index}/{len(domains)}")
        print(f"[+] Previous targets found: {total_targets}")

    for i in range(start_index, len(domains)):
        domain = domains[i]
        print(f"\n[{i+1}/{len(domains)}] Processing: {domain}")

        targets, search_url = scrape_shodan("2141724739", domain)

        if targets and search_url:
            print(f"    Found {len(targets)} targets")
            send_discord_webhook(webhook_url, domain, targets, search_url)
            total_targets += len(targets)
        else:
            print(f"    No results")

        mark_scanned(domain)
        save_progress(i + 1, total_targets)

        if i < len(domains) - 1:
            delay = random.uniform(3, 8)
            print(f"[*] Waiting {delay:.1f}s before next search...")
            time.sleep(delay)

    print("\n" + "=" * 60)
    print(f"[+] Complete: {total_targets} total targets found")
    print(f"[+] Scanned: {len(domains)} domains")
    print("=" * 60)


if __name__ == "__main__":
    main()
